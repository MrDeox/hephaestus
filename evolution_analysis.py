"""
AnÃ¡lise da EvoluÃ§Ã£o do Sistema RSI AI.
Verifica o progresso e desenvolvimento do sistema durante execuÃ§Ã£o.
"""

import sqlite3
import json
import pickle
from datetime import datetime, timezone
from pathlib import Path


def analyze_system_evolution():
    """Analisa a evoluÃ§Ã£o do sistema RSI AI."""
    print("ğŸ§  AnÃ¡lise da EvoluÃ§Ã£o do Sistema RSI AI")
    print("=" * 50)
    
    # 1. Analisar estado do sistema
    analyze_system_state()
    
    # 2. Analisar memÃ³ria episÃ³dica
    analyze_episodic_memory()
    
    # 3. Analisar memÃ³ria procedural
    analyze_procedural_memory()
    
    # 4. Analisar padrÃµes de aprendizado
    analyze_learning_patterns()
    
    # 5. ConclusÃµes
    print_conclusions()


def analyze_system_state():
    """Analisa o estado salvo do sistema."""
    try:
        with open('rsi_continuous_state.json', 'r') as f:
            state = json.load(f)
        
        metrics = state['metrics']
        uptime_hours = state['uptime_seconds'] / 3600
        
        print("ğŸ“Š Estado do Sistema:")
        print(f"   â±ï¸  Tempo de execuÃ§Ã£o: {uptime_hours:.2f} horas")
        print(f"   ğŸ”„ Ciclos completados: {state['cycle_count']}")
        print(f"   ğŸ“š Conhecimento adquirido: {metrics['total_knowledge_acquired']}")
        print(f"   âš¡ Habilidades desenvolvidas: {metrics['total_skills_learned']}")
        print(f"   ğŸ“ ExperiÃªncias registradas: {metrics['total_experiences']}")
        print(f"   âœ… ExpansÃµes bem-sucedidas: {metrics['successful_expansions']}")
        print(f"   âŒ ExpansÃµes falhadas: {metrics['failed_expansions']}")
        
        # Calcular velocidade de aprendizado
        if uptime_hours > 0:
            learning_rate = metrics['total_knowledge_acquired'] / uptime_hours
            print(f"   ğŸ“ˆ Taxa de aprendizado: {learning_rate:.1f} conceitos/hora")
        
        return metrics
        
    except Exception as e:
        print(f"âŒ Erro analisando estado: {e}")
        return {}


def analyze_episodic_memory():
    """Analisa a memÃ³ria episÃ³dica."""
    try:
        conn = sqlite3.connect('episodic_memory.db')
        cursor = conn.cursor()
        
        # Total de episÃ³dios
        cursor.execute('SELECT COUNT(*) FROM episodes')
        total_episodes = cursor.fetchone()[0]
        
        # EpisÃ³dios por tipo
        cursor.execute('''
            SELECT json_extract(content, '$.event') as event_type, COUNT(*) as count
            FROM episodes 
            WHERE event_type IS NOT NULL
            GROUP BY event_type
            ORDER BY count DESC
            LIMIT 5
        ''')
        event_types = cursor.fetchall()
        
        # EpisÃ³dios recentes (Ãºltima hora)
        cursor.execute('''
            SELECT COUNT(*) FROM episodes 
            WHERE datetime(timestamp) > datetime('now', '-1 hour')
        ''')
        recent_episodes = cursor.fetchone()[0]
        
        print(f"\nğŸ“š MemÃ³ria EpisÃ³dica:")
        print(f"   ğŸ“Š Total de episÃ³dios: {total_episodes}")
        print(f"   ğŸ• EpisÃ³dios na Ãºltima hora: {recent_episodes}")
        print(f"   ğŸ“ˆ Tipos de eventos mais frequentes:")
        
        for event_type, count in event_types:
            percentage = (count / total_episodes) * 100 if total_episodes > 0 else 0
            print(f"      - {event_type}: {count} ({percentage:.1f}%)")
        
        conn.close()
        return total_episodes
        
    except Exception as e:
        print(f"âŒ Erro analisando memÃ³ria episÃ³dica: {e}")
        return 0


def analyze_procedural_memory():
    """Analisa a memÃ³ria procedural."""
    try:
        with open('procedural_memory.pkl', 'rb') as f:
            data = pickle.load(f)
        
        skills = data.get('skills', {})
        stats = data.get('stats', {})
        
        print(f"\nâš¡ MemÃ³ria Procedural:")
        print(f"   ğŸ› ï¸  Total de habilidades: {len(skills)}")
        print(f"   ğŸ“Š Habilidades criadas: {stats.get('skills_created', 0)}")
        print(f"   ğŸ”„ Habilidades atualizadas: {stats.get('skills_updated', 0)}")
        
        # Analisar tipos de habilidades
        skill_types = {}
        for skill in skills.values():
            skill_type = skill.skill_type
            skill_types[skill_type] = skill_types.get(skill_type, 0) + 1
        
        print(f"   ğŸ“ˆ Tipos de habilidades:")
        for skill_type, count in skill_types.items():
            print(f"      - {skill_type}: {count}")
        
        # Habilidades mais complexas
        complex_skills = sorted(skills.values(), key=lambda s: s.complexity, reverse=True)[:3]
        print(f"   ğŸ§  Habilidades mais complexas:")
        for i, skill in enumerate(complex_skills, 1):
            print(f"      {i}. {skill.name} (complexidade: {skill.complexity:.2f})")
        
        return len(skills)
        
    except Exception as e:
        print(f"âŒ Erro analisando memÃ³ria procedural: {e}")
        return 0


def analyze_learning_patterns():
    """Analisa padrÃµes de aprendizado."""
    try:
        print(f"\nğŸ” PadrÃµes de Aprendizado:")
        
        # Analisar distribuiÃ§Ã£o temporal de episÃ³dios
        conn = sqlite3.connect('episodic_memory.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT 
                strftime('%H', timestamp) as hour,
                COUNT(*) as episodes_count
            FROM episodes 
            GROUP BY hour
            ORDER BY episodes_count DESC
            LIMIT 3
        ''')
        peak_hours = cursor.fetchall()
        
        print(f"   â° HorÃ¡rios de maior atividade:")
        for hour, count in peak_hours:
            print(f"      - {hour}:00 - {count} episÃ³dios")
        
        # Analisar evoluÃ§Ã£o da complexidade
        cursor.execute('''
            SELECT json_extract(content, '$.context.complexity') as complexity
            FROM episodes 
            WHERE complexity IS NOT NULL
            ORDER BY timestamp DESC
            LIMIT 100
        ''')
        complexities = [float(row[0]) for row in cursor.fetchall() if row[0]]
        
        if complexities:
            avg_complexity = sum(complexities) / len(complexities)
            print(f"   ğŸ§  Complexidade mÃ©dia das tarefas: {avg_complexity:.2f}")
            
            # TendÃªncia de complexidade
            recent_complexity = sum(complexities[:20]) / min(20, len(complexities))
            older_complexity = sum(complexities[-20:]) / min(20, len(complexities))
            
            if recent_complexity > older_complexity:
                print(f"   ğŸ“ˆ TendÃªncia: Aumento na complexidade das tarefas")
            else:
                print(f"   ğŸ“‰ TendÃªncia: EstabilizaÃ§Ã£o na complexidade")
        
        conn.close()
        
    except Exception as e:
        print(f"âŒ Erro analisando padrÃµes: {e}")


def print_conclusions():
    """Imprime conclusÃµes da anÃ¡lise."""
    print(f"\nğŸ¯ ConclusÃµes da AnÃ¡lise:")
    print(f"   âœ… Sistema estÃ¡ funcionalmente operacional")
    print(f"   âœ… Aprendizado contÃ­nuo estÃ¡ ativo")
    print(f"   âœ… MemÃ³ria episÃ³dica registrando experiÃªncias")
    print(f"   âœ… MemÃ³ria procedural desenvolvendo habilidades")
    print(f"   âš ï¸  ExpansÃµes autÃ´nomas precisam de ajustes")
    print(f"   ğŸ“Š Sistema demonstra capacidade de evoluÃ§Ã£o")
    
    print(f"\nğŸš€ PrÃ³ximos Passos Recomendados:")
    print(f"   1. Otimizar processo de expansÃ£o autÃ´noma")
    print(f"   2. Implementar uso efetivo das habilidades desenvolvidas")
    print(f"   3. Adicionar validaÃ§Ã£o de aprendizado")
    print(f"   4. Expandir fontes de conhecimento")
    print(f"   5. Implementar mÃ©tricas de qualidade")


if __name__ == "__main__":
    analyze_system_evolution()